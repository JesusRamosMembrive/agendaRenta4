# ğŸ§ª Prueba del Sistema de Quality Checks Post-Crawl

**Fecha de implementaciÃ³n:** 31 de Octubre de 2025
**Estado:** âœ… COMPLETADO - Listo para probar
**Siguiente paso:** Prueba end-to-end en la UI

---

## ğŸ“‹ Â¿QuÃ© se implementÃ³?

Se ha implementado un sistema completo que permite ejecutar **anÃ¡lisis de calidad automÃ¡ticos** despuÃ©s de cada crawl.

### CaracterÃ­sticas principales:

1. **Configurable por usuario**: Cada usuario decide quÃ© anÃ¡lisis ejecutar
2. **EjecuciÃ³n automÃ¡tica**: Los anÃ¡lisis se ejecutan solos al terminar el crawl
3. **EjecuciÃ³n manual**: TambiÃ©n se pueden ejecutar manualmente desde la UI
4. **Extensible**: FÃ¡cil agregar nuevos tipos de anÃ¡lisis
5. **No invasivo**: El crawl sigue siendo rÃ¡pido (anÃ¡lisis se ejecutan despuÃ©s)

---

## ğŸ”§ Componentes Implementados

### **Base de Datos**
- âœ… MigraciÃ³n `008_add_quality_check_config.sql` aplicada
- âœ… Tabla `quality_check_config` creada con datos iniciales
- âœ… ConfiguraciÃ³n para 3 usuarios con 2 checks cada uno

### **Backend**
- âœ… `calidad/post_crawl_runner.py` - Orquestador de checks
- âœ… `crawler/crawler.py` - IntegraciÃ³n con el crawler
- âœ… `crawler/routes.py` - 3 nuevas rutas API:
  - `GET /crawler/config/checks` - Obtener configuraciÃ³n
  - `POST /crawler/config/checks` - Guardar configuraciÃ³n
  - `POST /crawler/results/<id>/run-checks` - Ejecutar checks manualmente

### **Frontend**
- âœ… `templates/configuracion.html` - Nueva secciÃ³n "ğŸ”§ Herramientas de AnÃ¡lisis AutomÃ¡ticas"
  - Toggle switches para habilitar/deshabilitar
  - Checkboxes para ejecuciÃ³n automÃ¡tica
  - JavaScript para carga/guardado dinÃ¡mico

### **Tests**
- âœ… Todos los tests unitarios pasaron
- âœ… Batch processing de 3 URLs verificado
- âœ… IntegraciÃ³n completa verificada

---

## ğŸš€ CÃ³mo Probar (Paso a Paso)

### **PASO 1: Iniciar la AplicaciÃ³n**

```bash
cd /home/jesusramos/WorkSpace/agendaRenta4
python app.py
```

La aplicaciÃ³n deberÃ­a iniciar en: http://127.0.0.1:5000

---

### **PASO 2: Configurar Checks AutomÃ¡ticos** âš™ï¸

1. Abre el navegador: http://127.0.0.1:5000
2. Inicia sesiÃ³n con tu usuario
3. Ve a **"ConfiguraciÃ³n"** (menÃº lateral)
4. DesplÃ¡zate hasta **"ğŸ”§ Herramientas de AnÃ¡lisis AutomÃ¡ticas"**

DeberÃ­as ver:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”— ValidaciÃ³n de Enlaces Rotos        [Toggle] â”‚
â”‚ Verifica que todos los enlaces funcionen        â”‚
â”‚ correctamente                                    â”‚
â”‚ â˜ Ejecutar automÃ¡ticamente despuÃ©s del crawl   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ–¼ï¸ Calidad de ImÃ¡genes               [Toggle] â”‚
â”‚ Analiza alt text, tamaÃ±o, formato y carga      â”‚
â”‚ de imÃ¡genes                                      â”‚
â”‚ â˜ Ejecutar automÃ¡ticamente despuÃ©s del crawl   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ” AnÃ¡lisis SEO                       [Toggle] â”‚
â”‚ Verifica meta tags, tÃ­tulos y estructura SEO    â”‚
â”‚ (prÃ³ximamente)                                   â”‚
â”‚ [DESHABILITADO]                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

5. **Activa "Calidad de ImÃ¡genes":**
   - Click en el toggle switch (se pone rojo/activo)
   - Marca â˜‘ "Ejecutar automÃ¡ticamente despuÃ©s del crawl"

6. Click en **"ğŸ’¾ Guardar ConfiguraciÃ³n de AnÃ¡lisis"**
   - DeberÃ­as ver: "âœ… ConfiguraciÃ³n guardada correctamente"

---

### **PASO 3: Ejecutar un Crawl de Prueba** ğŸ•·ï¸

7. Ve a **"Crawler"** (menÃº lateral)

8. Click en **"â• Iniciar Nuevo Crawl"**

9. **Configura el crawl (IMPORTANTE: usa valores pequeÃ±os):**
   ```
   URL Base: https://www.r4.com
   Profundidad MÃ¡xima: 1
   MÃ¡ximo de URLs: 5
   ```
   âš ï¸ **Usar mÃ¡ximo 5 URLs para que sea rÃ¡pido**

10. Click en **"ğŸš€ Iniciar Crawl"**

11. **Espera a que termine** (~30-60 segundos)

---

### **PASO 4: Verificar EjecuciÃ³n AutomÃ¡tica** âœ…

Cuando el crawl termine, verifica:

#### **A. En los LOGS de la terminal:**

DeberÃ­as ver algo como esto:

```
INFO - Crawl completed: {'urls_discovered': 5, ...}
INFO - Running 1 automatic checks: ['image_quality']
INFO - Executing check: image_quality
INFO - Created batch 4 for 5 URLs
INFO - Checking https://www.r4.com/articulos-y-analisis...
INFO - âœ“ https://www.r4.com/articulos-y-analisis: error (score: 30, issues: 12)
INFO - Checking https://www.r4.com/renta-fija...
INFO - âœ“ https://www.r4.com/renta-fija: warning (score: 75, issues: 3)
INFO - Post-crawl checks completed for crawl run 3
INFO -   - image_quality: completed - Checked 5 sections, 5 successful
```

#### **B. En la UI - Dashboard de Calidad:**

12. Ve a **"ğŸ–¼ï¸ Calidad de ImÃ¡genes"** (menÃº lateral)

DeberÃ­as ver:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EstadÃ­sticas                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Total Checks: 5                                 â”‚
â”‚ PuntuaciÃ³n Media: 65                            â”‚
â”‚ âœ“ OK: 2                                         â”‚
â”‚ âš  Warnings: 2                                   â”‚
â”‚ âœ— Errors: 1                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Tabla con las 5 URLs analizadas y sus resultados
```

13. **Click en cualquier URL** para ver detalles:
    - Total de imÃ¡genes encontradas
    - ImÃ¡genes sin alt text
    - ImÃ¡genes grandes (>1MB)
    - ImÃ¡genes rotas
    - Formato subÃ³ptimal (JPG/PNG vs WebP)

---

### **PASO 5: Probar EjecuciÃ³n Manual** (Opcional)

Si quieres probar la ejecuciÃ³n manual:

14. Ve a **"ConfiguraciÃ³n"** de nuevo

15. **DESACTIVA** el checkbox "Ejecutar automÃ¡ticamente despuÃ©s del crawl"
    - MantÃ©n el toggle activado
    - Quita la marca de â˜ "Ejecutar automÃ¡ticamente..."

16. Guarda la configuraciÃ³n

17. Ejecuta otro crawl pequeÃ±o

18. Esta vez, el anÃ¡lisis **NO** deberÃ­a ejecutarse automÃ¡ticamente

19. Ve a la pÃ¡gina de **resultados del crawl**

20. DeberÃ­a haber un botÃ³n para ejecutar checks manualmente
    - (Nota: Esta UI aÃºn estÃ¡ pendiente de implementar en `crawler/results.html`)

---

## ğŸ¯ Checks Disponibles

| Check | Icono | Estado | DescripciÃ³n |
|-------|-------|--------|-------------|
| ValidaciÃ³n de Enlaces Rotos | ğŸ”— | âœ… Disponible | Verifica HTTP status de todos los enlaces |
| Calidad de ImÃ¡genes | ğŸ–¼ï¸ | âœ… Disponible | Alt text, tamaÃ±o, formato, enlaces rotos |
| AnÃ¡lisis SEO | ğŸ” | ğŸ”œ PrÃ³ximamente | Meta tags, tÃ­tulos, estructura |
| Performance | âš¡ | ğŸ”œ PrÃ³ximamente | Tiempos de carga, optimizaciÃ³n |
| Accesibilidad | â™¿ | ğŸ”œ PrÃ³ximamente | EstÃ¡ndares WCAG |

---

## ğŸ“Š Flujo del Sistema

```
1. Usuario habilita "image_quality" en ConfiguraciÃ³n
   â†“
2. Usuario ejecuta Crawl
   â†“
3. Crawl descubre URLs (proceso rÃ¡pido)
   â†“
4. Crawl finaliza exitosamente
   â†“
5. _run_post_crawl_checks() se ejecuta automÃ¡ticamente
   â†“
6. Lee quality_check_config para el usuario
   â†“
7. Encuentra: image_quality (enabled=True, auto=True)
   â†“
8. PostCrawlQualityRunner ejecuta BatchQualityCheckRunner
   â†“
9. Analiza cada URL secuencialmente (IMPORTANTE: uno tras otro)
   â†“
10. Guarda resultados en quality_checks
   â†“
11. Usuario ve resultados en "ğŸ–¼ï¸ Calidad de ImÃ¡genes"
```

---

## âš™ï¸ ConfiguraciÃ³n Actual

- **EjecuciÃ³n:** SECUENCIAL (un check tras otro, no en paralelo)
- **Timing:** POST-CRAWL (despuÃ©s del crawl, no durante)
- **Control:** Usuario decide quÃ© checks activar
- **AutomÃ¡tico:** Se puede configurar ejecuciÃ³n automÃ¡tica

**Â¿Por quÃ© secuencial?**
- Evita sobrecarga del servidor
- Logs mÃ¡s claros y fÃ¡ciles de seguir
- Evita saturar el sitio objetivo con requests HTTP simultÃ¡neos
- Suficientemente rÃ¡pido para anÃ¡lisis en background

---

## ğŸ—„ï¸ Base de Datos

### Tabla: `quality_check_config`

```sql
SELECT * FROM quality_check_config WHERE user_id = 1;
```

Resultado esperado:
```
 id | user_id |  check_type   | enabled | run_after_crawl
----+---------+---------------+---------+-----------------
  1 |       1 | broken_links  | f       | f
  2 |       1 | image_quality | f       | f
```

DespuÃ©s de configurar en la UI:
```
 id | user_id |  check_type   | enabled | run_after_crawl
----+---------+---------------+---------+-----------------
  1 |       1 | broken_links  | f       | f
  2 |       1 | image_quality | t       | t      â† âœ… ACTIVADO
```

---

## ğŸ› Troubleshooting

### Problema 1: No se ejecutan los checks automÃ¡ticos

**Verificar:**
```bash
# 1. Comprobar configuraciÃ³n en BD
PGPASSWORD=dev-password psql -U jesusramos -d agendaRenta4 -h localhost \
  -c "SELECT * FROM quality_check_config WHERE user_id = 1;"

# DeberÃ­a mostrar enabled=t y run_after_crawl=t
```

**SoluciÃ³n:** Vuelve a la UI y guarda la configuraciÃ³n de nuevo.

---

### Problema 2: Error "Module not found: calidad.post_crawl_runner"

**Verificar:**
```bash
ls -la calidad/post_crawl_runner.py
# DeberÃ­a existir el archivo
```

**SoluciÃ³n:** El archivo deberÃ­a existir. Si no, revisa que el commit incluyÃ³ todos los archivos.

---

### Problema 3: Checks tardan mucho tiempo

**Causa:** Tienes muchas URLs/secciones activas.

**SoluciÃ³n:**
- Usa `max_urls=5` en el crawl de prueba
- Los checks analizan cada imagen de cada URL, puede tardar
- Normal: ~5 segundos por URL con imÃ¡genes

---

### Problema 4: La secciÃ³n no aparece en ConfiguraciÃ³n

**Verificar:**
```bash
# Comprobar que el template tiene la secciÃ³n
grep -n "Herramientas de AnÃ¡lisis" templates/configuracion.html
# DeberÃ­a encontrar la lÃ­nea
```

**SoluciÃ³n:** Refresca la pÃ¡gina con Ctrl+Shift+R (forzar recarga sin cachÃ©).

---

## ğŸ“ Archivos Modificados/Creados

### Nuevos:
- `migrations/008_add_quality_check_config.sql`
- `calidad/post_crawl_runner.py`

### Modificados:
- `crawler/crawler.py` - MÃ©todo `_run_post_crawl_checks()`
- `crawler/routes.py` - 3 nuevas rutas API
- `templates/configuracion.html` - Nueva secciÃ³n + JavaScript
- `static/css/style.css` - Color de headers de tabla

---

## ğŸ¯ PrÃ³ximos Pasos (Futuro)

### Implementaciones pendientes:

1. **UI en crawler/results.html:**
   - Mostrar quÃ© checks se ejecutaron
   - Botones para re-ejecutar checks manualmente
   - Ver progreso de checks en ejecuciÃ³n

2. **UI en crawler/dashboard.html:**
   - Mostrar resumen de checks configurados antes de iniciar crawl
   - Indicador de quÃ© checks se ejecutarÃ¡n automÃ¡ticamente

3. **Nuevos checks:**
   - AnÃ¡lisis SEO (meta tags, tÃ­tulos, h1-h6)
   - Performance (tiempos de carga, tamaÃ±o total)
   - Accesibilidad (WCAG, contraste, estructura)

4. **Mejoras:**
   - Sistema de colas (Celery) para ejecuciÃ³n en background real
   - Notificaciones cuando terminan los checks
   - Exportar resultados a PDF/Excel
   - Comparar checks entre crawls (detectar mejoras/empeoramientos)

---

## âœ… Checklist de Prueba

Usa este checklist cuando pruebes:

- [ ] AplicaciÃ³n inicia sin errores
- [ ] PÃ¡gina "ConfiguraciÃ³n" carga correctamente
- [ ] SecciÃ³n "ğŸ”§ Herramientas de AnÃ¡lisis AutomÃ¡ticas" visible
- [ ] Se ven 2 checks disponibles (broken_links, image_quality)
- [ ] Toggle switches funcionan
- [ ] Checkbox "auto-run" funciona
- [ ] BotÃ³n "Guardar" funciona
- [ ] Alert "âœ… ConfiguraciÃ³n guardada" aparece
- [ ] Crawl se ejecuta correctamente
- [ ] Logs muestran "Running 1 automatic checks"
- [ ] Logs muestran "Post-crawl checks completed"
- [ ] PÃ¡gina "ğŸ–¼ï¸ Calidad de ImÃ¡genes" muestra resultados
- [ ] EstadÃ­sticas se calculan correctamente
- [ ] Tabla muestra URLs analizadas
- [ ] Detalles de cada check son visibles

---

## ğŸ“ Contacto / Notas

**Desarrollador:** Claude + Jesus Ramos
**Fecha:** 31 de Octubre de 2025
**Branch:** stage2
**Commit pendiente:** SÃ­ (hacer commit de todos los cambios)

**Archivos listos para commit:**
```bash
git status
# DeberÃ­as ver:
# - migrations/008_add_quality_check_config.sql
# - calidad/post_crawl_runner.py
# - crawler/crawler.py (modificado)
# - crawler/routes.py (modificado)
# - templates/configuracion.html (modificado)
# - static/css/style.css (modificado)
```

---

## ğŸ‰ ConclusiÃ³n

El sistema estÃ¡ **100% implementado y testeado** en backend. Solo falta probarlo en la UI para verificar que todo funciona end-to-end.

**EstimaciÃ³n de tiempo de prueba:** 10-15 minutos

**Siguientes pasos recomendados:**
1. Probar flujo completo segÃºn esta guÃ­a
2. Si funciona: hacer commit y merge
3. Si falla: revisar logs y reportar error

Â¡Buena suerte con las pruebas! ğŸš€
