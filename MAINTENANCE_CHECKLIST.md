# Maintenance Checklist
## Control de Crecimiento de CÃ³digo y Calidad

**PropÃ³sito**: Evitar que "vibe coding" se convierta en "dead coding"
**Frecuencia**: Ejecutar DESPUÃ‰S de cada fase de implementaciÃ³n (entre Phase 3.1, 3.2, 3.3, etc.)
**Tiempo estimado**: 2-3 horas por revisiÃ³n

---

## ğŸ¯ FilosofÃ­a de Mantenimiento

> **"El mejor cÃ³digo es el que no escribes"**

### Principios clave
1. **Eliminar antes que optimizar** - CÃ³digo muerto es peor que cÃ³digo lento
2. **Simplificar antes que refactorizar** - Menos lÃ­neas = menos bugs
3. **Medir antes que asumir** - Datos > IntuiciÃ³n
4. **Documentar decisiones** - El "por quÃ©" es mÃ¡s importante que el "cÃ³mo"

### SeÃ±ales de alerta ğŸš¨
- âŒ Funciones nunca usadas
- âŒ CÃ³digo duplicado en 3+ lugares
- âŒ Archivos >500 lÃ­neas
- âŒ Funciones >50 lÃ­neas
- âŒ Imports no usados
- âŒ Comentarios desactualizados
- âŒ Tests que no fallan nunca (no estÃ¡n probando nada real)

---

## âœ… Checklist de Mantenimiento

### PARTE 1: MÃ©tricas de CÃ³digo (15 minutos)

#### 1.1 TamaÃ±o de archivos
```bash
# Ejecutar en terminal
find . -name "*.py" -type f ! -path "./venv/*" ! -path "./.venv/*" -exec wc -l {} + | sort -rn | head -20
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Hay archivos >500 lÃ­neas?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Planificar refactoring** (ver secciÃ³n PARTE 3)

- [ ] Â¿`app.py` tiene <1,000 lÃ­neas?
  - âœ… SÃ â†’ Continuar
  - âŒ NO â†’ **CRÃTICO**: Mover lÃ³gica a mÃ³dulos

**Meta**: NingÃºn archivo >500 lÃ­neas, `app.py` <1,000 lÃ­neas

---

#### 1.2 Complejidad ciclomÃ¡tica
```bash
# Instalar radon si no estÃ¡ instalado
pip install radon

# Medir complejidad
radon cc . -a -nb --min C
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Hay funciones con complejidad â‰¥C (>10)?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Simplificar funciÃ³n** (extraer subfunciones)

**Meta**: MÃ¡xima complejidad B (6-10), idealmente A (1-5)

---

#### 1.3 CÃ³digo duplicado
```bash
# Detectar cÃ³digo duplicado
pylint --disable=all --enable=duplicate-code .
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Hay bloques duplicados en 3+ archivos?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Extraer a utilidad comÃºn** en `calidad/base.py` o `utils.py`

**Meta**: Zero duplicaciÃ³n en 3+ lugares

---

#### 1.4 Imports no usados
```bash
# Detectar imports no usados
pip install autoflake
autoflake --check --remove-all-unused-imports -r .
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Hay imports no usados?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Eliminar automÃ¡ticamente**:
```bash
autoflake --remove-all-unused-imports --in-place -r .
```

**Meta**: Zero imports no usados

---

#### 1.5 Funciones no usadas
```bash
# Detectar funciones que nunca se llaman
vulture . --min-confidence 80
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Hay funciones/variables que nunca se usan?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Eliminar o documentar por quÃ© estÃ¡n** (futuro uso)

**Meta**: Zero cÃ³digo muerto (o justificar explÃ­citamente)

---

### PARTE 2: Base de Datos (20 minutos)

#### 2.1 Revisar tamaÃ±o de base de datos
```bash
# Conectar a PostgreSQL y ejecutar
psql $DATABASE_URL -c "
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size,
    pg_total_relation_size(schemaname||'.'||tablename) AS size_bytes
FROM pg_tables
WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
ORDER BY size_bytes DESC;
"
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Hay tablas >100MB?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Considerar archivado/particionamiento**

- [ ] Â¿`discovered_urls` tiene >10,000 filas?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Implementar limpieza de URLs antiguas** (>6 meses)

**Meta**: Tablas <100MB, `discovered_urls` <10K filas

---

#### 2.2 Verificar Ã­ndices
```bash
# Listar Ã­ndices
psql $DATABASE_URL -c "
SELECT
    schemaname,
    tablename,
    indexname,
    indexdef
FROM pg_indexes
WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
ORDER BY tablename, indexname;
"
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Hay consultas lentas (>1s) sin Ã­ndice?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Crear Ã­ndice** en columnas WHERE/JOIN

- [ ] Â¿Hay Ã­ndices no usados?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Eliminar Ã­ndice** (ocupan espacio)

**Meta**: Ãndices solo en columnas realmente consultadas

---

#### 2.3 Queries N+1
**Revisar manualmente** en cÃ³digo:

Â¿Hay loops que hacen consultas dentro?
```python
# âŒ MAL - N+1 query
for url in urls:
    details = cursor.execute("SELECT * FROM url_changes WHERE url_id = %s", (url['id'],))

# âœ… BIEN - 1 query
url_ids = [u['id'] for u in urls]
cursor.execute("SELECT * FROM url_changes WHERE url_id = ANY(%s)", (url_ids,))
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Hay loops con consultas SQL dentro?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Refactorizar a batch query**

**Meta**: Zero N+1 queries

---

### PARTE 3: Arquitectura y DiseÃ±o (30 minutos)

#### 3.1 Responsabilidades de archivos
**Revisar manualmente**:

Â¿Cada archivo tiene UNA responsabilidad clara?
- `app.py` â†’ Solo rutas y configuraciÃ³n Flask
- `crawler/engine.py` â†’ Solo lÃ³gica de crawling
- `calidad/imagenes.py` â†’ Solo verificaciÃ³n de imÃ¡genes
- `db.py` â†’ Solo conexiones y queries de base de datos

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Hay archivos que hacen "demasiado"?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Dividir en mÃ³dulos** (Single Responsibility Principle)

**SeÃ±ales de archivo "demasiado grande"**:
- >500 lÃ­neas
- >10 funciones diferentes
- Imports de >5 mÃ³dulos diferentes
- Mezcla de lÃ³gica de negocio + presentaciÃ³n + datos

---

#### 3.2 DuplicaciÃ³n de lÃ³gica
**Buscar patrones repetidos**:

```bash
# Buscar cÃ³digo similar
grep -r "BeautifulSoup" --include="*.py" | wc -l
grep -r "requests.get" --include="*.py" | wc -l
grep -r "cursor.execute" --include="*.py" | wc -l
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿La misma lÃ³gica se repite en 3+ archivos?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Extraer a `calidad/base.py` o `utils.py`**

**Ejemplo de extracciÃ³n**:
```python
# Antes (repetido en imagenes.py, ctas.py, textos.py)
soup = BeautifulSoup(html_content, 'html.parser')
for script in soup(['script', 'style', 'noscript']):
    script.decompose()
text = soup.get_text(separator=' ', strip=True)

# DespuÃ©s (una vez en calidad/base.py)
def extract_clean_text(html_content):
    """Extrae texto limpio de HTML"""
    soup = BeautifulSoup(html_content, 'html.parser')
    for script in soup(['script', 'style', 'noscript']):
        script.decompose()
    return soup.get_text(separator=' ', strip=True)
```

---

#### 3.3 JerarquÃ­a de dependencias
**Verificar que las dependencias van en una direcciÃ³n**:

```
templates/
    â†“ (usa)
app.py
    â†“ (importa)
calidad/*.py
    â†“ (importa)
calidad/base.py
    â†“ (importa)
utils.py
```

**Reglas**:
- âŒ `utils.py` NO debe importar de `calidad/`
- âŒ `calidad/base.py` NO debe importar de `calidad/imagenes.py`
- âŒ `calidad/*.py` NO debe importar de `app.py`

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Hay dependencias circulares?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Refactorizar jerarquÃ­a**

---

### PARTE 4: Performance (30 minutos)

#### 4.1 Tiempo de crawl completo
```bash
# Ejecutar crawl de prueba y medir tiempo
time python -c "
from crawler.engine import run_crawl
import time
start = time.time()
run_crawl('https://example.com', max_depth=2, max_urls=50)
elapsed = time.time() - start
print(f'Tiempo: {elapsed:.1f}s para 50 URLs')
print(f'ProyecciÃ³n para 173 URLs: {elapsed * 173/50 / 60:.1f} minutos')
"
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Tiempo proyectado para 173 URLs <30 minutos?
  - âœ… SÃ â†’ Continuar
  - âŒ NO â†’ **Optimizar** (ver secciÃ³n 4.3)

**Meta**: <30 minutos para crawl completo de 173 URLs

---

#### 4.2 Uso de memoria
```bash
# Monitorear memoria durante crawl
python -m memory_profiler crawler/engine.py
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Uso de memoria <512MB durante crawl?
  - âœ… SÃ â†’ Continuar
  - âŒ NO â†’ **Revisar leaks de memoria** (cerrar conexiones, liberar objetos grandes)

**Meta**: <512MB de RAM (compatible con plan gratuito de Render)

---

#### 4.3 Optimizaciones comunes

**Si el crawl es lento**, aplicar estas tÃ©cnicas:

1. **Requests concurrentes** (usar `asyncio` o `concurrent.futures`)
```python
# Antes
for url in urls:
    response = requests.get(url)
    process(response)

# DespuÃ©s
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=5) as executor:
    responses = executor.map(lambda u: requests.get(u, timeout=5), urls)
    for response in responses:
        process(response)
```

2. **Cache de HTML** (no re-crawlear si no cambiÃ³)
```python
# Guardar hash del contenido
content_hash = hashlib.md5(html_content.encode()).hexdigest()
if content_hash == previous_hash:
    print("No cambiÃ³, skip checks")
    return
```

3. **Rate limiting inteligente** (no esperar si servidor es rÃ¡pido)
```python
# Ajustar delay segÃºn response time
if response.elapsed.total_seconds() < 0.5:
    time.sleep(0.1)  # Servidor rÃ¡pido, poco delay
else:
    time.sleep(1.0)  # Servidor lento, mÃ¡s delay
```

---

### PARTE 5: Testing y Calidad (30 minutos)

#### 5.1 Cobertura de tests
```bash
# Ejecutar tests con cobertura
pytest --cov=. --cov-report=html
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Cobertura >70%?
  - âœ… SÃ â†’ Continuar
  - âŒ NO â†’ **Agregar tests** para funciones crÃ­ticas

**Funciones crÃ­ticas que DEBEN tener tests**:
- Verificadores de calidad (`calidad/*.py`)
- Parseo de HTML (extracciÃ³n de imÃ¡genes, CTAs, etc.)
- LÃ³gica de notificaciones (cuÃ¡ndo enviar email)
- Queries de base de datos complejas

**Meta**: >70% cobertura (no buscar 100%, es unrealistic)

---

#### 5.2 Tests que siempre pasan (falsos positivos)
**Revisar manualmente** cada test:

Â¿El test realmente valida algo?
```python
# âŒ MAL - Test que nunca falla
def test_images_checker():
    checker = ImageChecker()
    assert checker is not None  # Esto SIEMPRE pasa

# âœ… BIEN - Test con validaciÃ³n real
def test_images_checker_detects_missing_alt():
    html = '<img src="test.jpg">'  # Sin alt
    checker = ImageChecker()
    result = checker.check_url('http://test.com', html)
    assert len(result['issues']) > 0
    assert any('alt' in issue.lower() for issue in result['issues'])
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Todos los tests realmente validan comportamiento?
  - âœ… SÃ â†’ Continuar
  - âŒ NO â†’ **Mejorar tests** o eliminar tests inÃºtiles

---

#### 5.3 Linting y formateo
```bash
# Verificar estilo de cÃ³digo
flake8 . --max-line-length=120 --exclude=venv,.venv,migrations

# Formatear cÃ³digo automÃ¡ticamente
black . --line-length=120
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿CÃ³digo pasa linting sin errores?
  - âœ… SÃ â†’ Continuar
  - âŒ NO â†’ **Corregir errores** (o ajustar reglas si son demasiado estrictas)

**Meta**: CÃ³digo consistente, fÃ¡cil de leer

---

### PARTE 6: Seguridad (15 minutos)

#### 6.1 Secretos en cÃ³digo
```bash
# Buscar posibles secretos hardcodeados
grep -r "password\s*=" --include="*.py" .
grep -r "api_key\s*=" --include="*.py" .
grep -r "secret\s*=" --include="*.py" .
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Hay secretos hardcodeados?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Mover a variables de entorno** (.env)

**Meta**: Zero secretos en cÃ³digo

---

#### 6.2 SQL Injection
**Revisar queries manualmente**:

Â¿Todas las queries usan placeholders?
```python
# âŒ VULNERABLE
cursor.execute(f"SELECT * FROM users WHERE name = '{user_input}'")

# âœ… SEGURO
cursor.execute("SELECT * FROM users WHERE name = %s", (user_input,))
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Todas las queries usan placeholders (%s, %d)?
  - âœ… SÃ â†’ Continuar
  - âŒ NO â†’ **Refactorizar queries inmediatamente**

**Meta**: Zero SQL injection vulnerabilities

---

#### 6.3 XSS (Cross-Site Scripting)
**Revisar templates Jinja2**:

Â¿Usamos `{{ var }}` (escapado) o `{{ var|safe }}` (sin escapar)?
```jinja2
{# âœ… SEGURO - Jinja2 escapa automÃ¡ticamente #}
<p>{{ user_input }}</p>

{# âŒ PELIGROSO - Solo si estÃ¡s 100% seguro #}
<p>{{ user_input|safe }}</p>
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Evitamos `|safe` a menos que sea necesario?
  - âœ… SÃ â†’ Continuar
  - âŒ NO â†’ **Eliminar |safe** o validar input primero

**Meta**: MÃ­nimo uso de `|safe`, siempre con validaciÃ³n previa

---

### PARTE 7: DocumentaciÃ³n (15 minutos)

#### 7.1 README.md actualizado
**Verificar que README incluye**:
- [ ] DescripciÃ³n del proyecto
- [ ] Instrucciones de instalaciÃ³n (`pip install -r requirements.txt`)
- [ ] Variables de entorno requeridas (`.env.example`)
- [ ] CÃ³mo ejecutar la aplicaciÃ³n (`python app.py`)
- [ ] CÃ³mo ejecutar tests (`pytest`)
- [ ] Screenshot del dashboard (si es portfolio)

---

#### 7.2 Docstrings en funciones
**Revisar que funciones complejas tienen docstrings**:
```python
# âœ… BIEN
def check_image_quality(url, html_content):
    """
    Verifica la calidad de todas las imÃ¡genes en una URL.

    Args:
        url (str): URL de la pÃ¡gina a verificar
        html_content (str): HTML de la pÃ¡gina

    Returns:
        dict: Diccionario con 'issues', 'warnings', 'passed'
    """
    pass
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Funciones complejas (>20 lÃ­neas) tienen docstrings?
  - âœ… SÃ â†’ Continuar
  - âŒ NO â†’ **Agregar docstrings**

**Meta**: Funciones >20 lÃ­neas con docstrings descriptivos

---

#### 7.3 Comentarios actualizados
**Buscar comentarios obsoletos**:
```bash
# Buscar TODOs antiguos
grep -r "TODO" --include="*.py" .
grep -r "FIXME" --include="*.py" .
grep -r "HACK" --include="*.py" .
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Hay TODOs/FIXMEs de hace >1 mes?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Resolver o eliminar** (si ya no aplica)

**Meta**: Comentarios siempre relevantes

---

### PARTE 8: Git y Versionado (10 minutos)

#### 8.1 Commits descriptivos
**Revisar Ãºltimos 10 commits**:
```bash
git log --oneline -10
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Commits tienen mensajes descriptivos?
  - âœ… SÃ (ej: "Add image quality checker with alt text validation")
  - âŒ NO (ej: "fix", "wip", "test")

**Buenas prÃ¡cticas**:
- Usar prefijos: `feat:`, `fix:`, `refactor:`, `docs:`
- Mensaje en imperativo: "Add" no "Added"
- MÃ¡ximo 72 caracteres en primera lÃ­nea

---

#### 8.2 Branches limpias
```bash
# Listar branches
git branch -a
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Hay branches obsoletas (mergeadas hace >1 mes)?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Eliminar branches viejas**:
```bash
git branch -d branch-name
git push origin --delete branch-name
```

**Meta**: Solo branches activas (master, develop, feature-actual)

---

### PARTE 9: Decisiones y Trade-offs (15 minutos)

#### 9.1 Documentar decisiones tÃ©cnicas
**Crear archivo `DECISIONS.md` si no existe**:

```markdown
# Decisiones TÃ©cnicas

## 2025-11-10: Por quÃ© BeautifulSoup y no Scrapy
**Problema**: Necesitamos parsear HTML de 173 URLs
**Opciones consideradas**:
1. BeautifulSoup - Simple, sÃ­ncrono
2. Scrapy - Framework completo, mÃ¡s complejo
**DecisiÃ³n**: BeautifulSoup
**RazÃ³n**: Simplicidad > Performance para 173 URLs. Scrapy es overkill.
**Trade-off**: Si crecemos a >1000 URLs, reconsiderar Scrapy.

## 2025-11-15: Por quÃ© no usar LanguageTool API para todo
**Problema**: Necesitamos detectar errores de ortografÃ­a/gramÃ¡tica
**Opciones consideradas**:
1. LanguageTool API (gratuita, rate limited)
2. pyspellchecker (offline, solo ortografÃ­a)
**DecisiÃ³n**: pyspellchecker + LanguageTool API (opcional)
**RazÃ³n**: pyspellchecker es suficiente para 90% de casos, sin rate limits
**Trade-off**: GramÃ¡tica avanzada requiere LanguageTool (usar solo si usuario lo pide)
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Documentamos decisiones importantes?
  - âœ… SÃ â†’ Continuar
  - âŒ NO â†’ **Crear `DECISIONS.md`** y agregar decisiÃ³n actual

---

### PARTE 10: ReflexiÃ³n y PlanificaciÃ³n (15 minutos)

#### 10.1 Â¿QuÃ© funcionÃ³ bien?
**Escribir en `MAINTENANCE_LOG.md`**:
```markdown
# Maintenance Log

## 2025-11-10 - Post Phase 3.1 (ImÃ¡genes)

### âœ… QuÃ© funcionÃ³ bien
- La arquitectura modular (`calidad/imagenes.py`) es fÃ¡cil de mantener
- Tests cubrieron 85% del cÃ³digo nuevo
- Pillow es muy rÃ¡pido para analizar imÃ¡genes

### âš ï¸ QuÃ© puede mejorar
- Algunos falsos positivos con imÃ¡genes SVG (tratar diferente)
- Queries a discovered_urls podrÃ­an optimizarse (agregar Ã­ndice)
- Falta documentaciÃ³n en funciones de utilidad

### ğŸ”§ Acciones tomadas
- [x] Agregado Ã­ndice en discovered_urls.url
- [x] Agregado manejo especial para SVG
- [ ] Pendiente: Documentar funciones en calidad/base.py

### ğŸ“Š MÃ©tricas
- app.py: 1,200 lÃ­neas (era 1,647, reducido en refactoring)
- calidad/imagenes.py: 350 lÃ­neas
- Tiempo de crawl: 18 minutos para 173 URLs
- Cobertura de tests: 78%
```

---

#### 10.2 Â¿Hay cÃ³digo que nunca se usÃ³?
**Revisar funcionalidad**:

DespuÃ©s de 1 semana en producciÃ³n, Â¿se usÃ³ esta feature?
```bash
# Ver logs de uso
grep "image_quality_check" logs/app.log | wc -l
```

**Criterios de evaluaciÃ³n**:
- [ ] Â¿Hay features que nadie usa despuÃ©s de 1-2 semanas?
  - âœ… NO â†’ Continuar
  - âŒ SÃ â†’ **Considerar eliminar** (o preguntar al usuario)

**Regla**: Si despuÃ©s de 1 mes nadie usa una feature, probablemente no la necesitan.

---

#### 10.3 Planificar siguiente fase
**Actualizar `.claude/01-current-phase.md`**:

```markdown
# Current Phase: Maintenance - Post Phase 3.1

## âœ… Completado
- [x] Phase 3.1: VerificaciÃ³n de ImÃ¡genes
- [x] Refactoring de crawler a mÃ³dulo separado
- [x] ReducciÃ³n de app.py de 1,647 â†’ 1,200 lÃ­neas

## ğŸ“Š Estado Actual
- Base de datos: 3,450 URLs descubiertas
- Ãšltimo crawl: 2025-11-10 14:30
- Issues encontrados: 12 imÃ¡genes sin alt, 3 imÃ¡genes rotas

## ğŸ¯ Siguiente Fase: Phase 3.2 (CTAs)
- Fecha estimada de inicio: 2025-11-12
- DuraciÃ³n estimada: 1.5 semanas
- Dependencias: Ninguna (puede empezar ya)

## âš ï¸ Pendientes antes de Phase 3.2
- [ ] Resolver issue #23: Falsos positivos con SVG
- [ ] Optimizar query en crawler/results (agregar Ã­ndice)
- [ ] Actualizar README con screenshots de dashboard
```

---

## ğŸ“‹ Resumen Ejecutivo (Copiar y pegar despuÃ©s de cada maintenance)

### Checklist RÃ¡pida (5 minutos)
- [ ] `app.py` <1,000 lÃ­neas
- [ ] NingÃºn archivo >500 lÃ­neas
- [ ] Zero imports no usados (ejecutar autoflake)
- [ ] Zero cÃ³digo duplicado en 3+ lugares
- [ ] Zero secretos hardcodeados
- [ ] Zero SQL injection vulnerabilities
- [ ] Cobertura de tests >70%
- [ ] Tiempo de crawl <30 minutos
- [ ] README actualizado
- [ ] DECISIONS.md con decisiones importantes
- [ ] `.claude/01-current-phase.md` actualizado

---

## ğŸš¨ DecisiÃ³n: Â¿Refactorizar o Continuar?

### SI la respuesta a ALGUNA de estas preguntas es SÃ, hacer refactoring ANTES de continuar:
- [ ] Â¿`app.py` >1,500 lÃ­neas?
- [ ] Â¿Hay archivos >1,000 lÃ­neas?
- [ ] Â¿Hay funciones con complejidad ciclomÃ¡tica >15?
- [ ] Â¿Tiempo de crawl >45 minutos?
- [ ] Â¿Hay vulnerabilidades de seguridad (SQL injection, XSS)?
- [ ] Â¿Tests estÃ¡n fallando en producciÃ³n?

### SI todas son NO, es seguro continuar con siguiente fase.

---

## ğŸ¯ Objetivo Final de Maintenance

**DespuÃ©s de cada fase, el cÃ³digo debe estar**:
- âœ… MÃ¡s simple que antes (menos lÃ­neas, menos complejidad)
- âœ… MÃ¡s rÃ¡pido que antes (mejor performance)
- âœ… MÃ¡s seguro que antes (sin vulnerabilidades nuevas)
- âœ… Mejor documentado que antes
- âœ… MÃ¡s fÃ¡cil de entender para tu "yo del futuro"

**Si no cumple estos criterios, NO continuar con siguiente fase.**

---

## ğŸ“š Herramientas Recomendadas

### InstalaciÃ³n Ãºnica (ejecutar una vez)
```bash
pip install radon autoflake vulture flake8 black pytest pytest-cov memory-profiler
```

### Alias Ãºtiles para `.bashrc` o `.zshrc`
```bash
alias check-code="flake8 . --max-line-length=120 --exclude=venv,.venv"
alias format-code="black . --line-length=120"
alias clean-imports="autoflake --remove-all-unused-imports --in-place -r ."
alias find-dead-code="vulture . --min-confidence 80"
alias check-complexity="radon cc . -a -nb --min C"
alias test-coverage="pytest --cov=. --cov-report=html && open htmlcov/index.html"
```

---

## ğŸ”„ Frecuencia de EjecuciÃ³n

| Checklist | Frecuencia | Tiempo |
|-----------|------------|--------|
| **PARTE 1: MÃ©tricas** | DespuÃ©s de cada fase | 15 min |
| **PARTE 2: Base de Datos** | DespuÃ©s de cada fase | 20 min |
| **PARTE 3: Arquitectura** | Cada 2-3 fases | 30 min |
| **PARTE 4: Performance** | Cada 2-3 fases | 30 min |
| **PARTE 5: Testing** | DespuÃ©s de cada fase | 30 min |
| **PARTE 6: Seguridad** | Cada fase (crÃ­tico) | 15 min |
| **PARTE 7: DocumentaciÃ³n** | Cada 2-3 fases | 15 min |
| **PARTE 8: Git** | Cada fase | 10 min |
| **PARTE 9: Decisiones** | DespuÃ©s de decisiones importantes | 15 min |
| **PARTE 10: ReflexiÃ³n** | DespuÃ©s de cada fase | 15 min |

**Total tiempo por maintenance completo**: ~2-3 horas

---

## ğŸ’¡ FilosofÃ­a Final

> "No escribas cÃ³digo que tu yo del futuro odie leer"
>
> "El mejor refactor es el que elimina cÃ³digo, no el que lo reorganiza"
>
> "Si no estÃ¡s usando una feature despuÃ©s de 1 mes, probablemente no la necesitas"

**MantÃ©n el cÃ³digo simple, limpio, y enfocado en resolver problemas reales.**

---

**Documento creado**: 2025-10-31
**Ãšltima actualizaciÃ³n**: 2025-10-31
**Autor**: Claude Code + JesÃºs Ramos
**PropÃ³sito**: Controlar crecimiento de cÃ³digo entre fases de Stage 3
